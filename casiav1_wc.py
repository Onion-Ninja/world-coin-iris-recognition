# -*- coding: utf-8 -*-
"""casiaV1_wc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dwUR918k5q3SHab8pRidKCl3GoWWn-Ns
"""

# !pip install onnx onnxruntime pydantic==1.10.16 huggingface-hub pyyaml
# !pip install --no-deps open-iris

import iris
import numpy as np

print(iris.__version__)

# Upload CASIA.zip
# Unzip CASIA V1
# !unzip -q /content/CASIA1.zip

import cv2
import matplotlib.pyplot as plt

img_pixels = cv2.imread("home/nishkal/datasets/iris_datasets/CASIA/V3/CASIA-IrisV3/CASIA-Iris-Interval/001/L/S1001L01.jpg", cv2.IMREAD_GRAYSCALE)
plt.imshow(img_pixels, cmap='gray')

iris_pipeline = iris.IRISPipeline()
output = iris_pipeline(iris.IRImage(img_data=img_pixels, image_id="image_id", eye_side="right"))
output.keys()

# Verify IRISPipeline inference call finished without any exception being raised
output["error"] is None

"""Available fields in `output["iris_template"]` are: """ + str(output["iris_template"].__fields__)

num_codes = len(output["iris_template"].iris_codes)
code_shape = output["iris_template"].iris_codes[0].shape

f"""Number of returned iris codes is equal to {num_codes} and each code shape is {code_shape}"""

output["metadata"]

"""## Debug Env"""

iris_pipeline = iris.IRISPipeline(env=iris.IRISPipeline.DEBUGGING_ENVIRONMENT)

output = iris_pipeline(iris.IRImage(img_data=img_pixels, image_id="image_id", eye_side="right"))

output.keys()

iris_visualizer = iris.visualisation.IRISVisualizer()

import matplotlib.pyplot as plt

canvas = iris_visualizer.plot_ir_image(iris.IRImage(img_data=img_pixels, eye_side="right"))
plt.show()

canvas = iris_visualizer.plot_iris_template(output["iris_template"])
plt.show()

iris_pipeline.call_trace['segmentation']

canvas = iris_visualizer.plot_segmentation_map(
    ir_image=iris.IRImage(img_data=img_pixels, eye_side="right"),
    segmap=iris_pipeline.call_trace['segmentation'],
)
plt.show()

canvas = iris_visualizer.plot_all_geometry(
    ir_image=iris.IRImage(img_data=img_pixels, eye_side="right"),
    geometry_polygons=iris_pipeline.call_trace['vectorization'],
    eye_orientation=iris_pipeline.call_trace['eye_orientation'],
    eye_center=iris_pipeline.call_trace['eye_center_estimation'],
)
plt.show()

canvas = iris_visualizer.plot_all_geometry(
    ir_image=iris.IRImage(img_data=img_pixels, eye_side="right"),
    geometry_polygons=iris_pipeline.call_trace['geometry_estimation'],
    eye_orientation=iris_pipeline.call_trace['eye_orientation'],
    eye_center=iris_pipeline.call_trace['eye_center_estimation'],
)
plt.show()

canvas = iris_visualizer.plot_normalized_iris(
    normalized_iris=iris_pipeline.call_trace['normalization'],
)
plt.show()

canvas = iris_visualizer.plot_iris_template(
    iris_template=iris_pipeline.call_trace['encoder'],
)
plt.show()

"""# CASIA V1 Dataset"""

## Helper functions to run the pipeline
# Scans the dataset and returns all the filenames along with their metadata USER ID, Eye Side, Session Number = optional for CASIA V1
import os
import re

# Takes the filename as input and parses out the User ID, Image Number, SessionNo/EyeSide
def parse_filename(filename, database = "CASIAV1"):
  base = os.path.basename(filename)
  name, extension = os.path.splitext(base)

  match = re.match(r"(\d{3})_(\d)_(\d+)", name)
  if not match:
    raise ValueError(f"Invalid filename format: {filename}")

  user_id, session_number, image_number = match.groups()
  eye_side = "none"
  return {
    "user_id": user_id,
    "session_number": session_number,
    "image_number": image_number,
    "eye_side": eye_side
  }

# Takes the directory path as input
# Returns a dictionary of All image filepaths, and file metadata
def scan_files(path = "/content/CASIA1"):
  allfiles = []
  user_ids =set()

  for root, dirs, files in os.walk(path):
    for f in files:
      if f.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp')):
        full_path = os.path.join(root, f)
        try:
          meta = parse_filename(f)
          meta["filepath"] = full_path
          allfiles.append(meta)
          user_ids.add(meta["user_id"])
        except ValueError as e:
          print(f"Skipping {full_path}: {e}")
  return allfiles, sorted(list(user_ids))


file_metadata = parse_filename("/content/001_1_1.jpg")
print(file_metadata)

allfiles, user_ids = scan_files()
print(allfiles)
print(user_ids)

def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)

from tqdm import tqdm
# function that runs the whole pipeline
def pipeline(dataset_path = "/content/CASIA1", save_visuals = True, save_embeddings = False):

  ## Main Pipeline to run the model on all images
  print(f"Scanning Dataset {dataset_path}")
  files, user_ids = scan_files(dataset_path)
  print(f"Found {len(files)} files")

  # init debug env
  print("Initialising Iris Pipeline")
  iris_pipeline = iris.IRISPipeline(env=iris.IRISPipeline.DEBUGGING_ENVIRONMENT)

  # init visualizer
  print("Initialising Iris Visualizer")
  iris_visualizer = iris.visualisation.IRISVisualizer()

  # Step 3: Prepare output dirs
  output_dir = os.path.join("/content", "outputs")
  seg_dir = os.path.join(output_dir, "segmentation")
  norm_dir = os.path.join(output_dir, "normalized")
  temp_dir = os.path.join(output_dir, "templates")
  code_dir = os.path.join(output_dir, "codes")

  print(output_dir, seg_dir, norm_dir, temp_dir)

  # Ensure folders exists
  if save_visuals:
    ensure_dir(seg_dir)
    ensure_dir(norm_dir)
    ensure_dir(temp_dir)
    ensure_dir(code_dir)

  results = []

  print(f"Fields: {files[0].keys()}")
  for file_meta in tqdm(files, desc="Processing iris images"):
    img_path = file_meta["filepath"]
    filename = os.path.basename(img_path)
    name, _ = os.path.splitext(filename)

    try:
      image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
      if image is None:
        raise IOError(f"Could not read Image {img_path}")
      iris_image = iris.IRImage(img_data=image, image_id=name, eye_side="left")
      output = iris_pipeline(iris_image)
      # Save seg result:
      seg_path = os.path.join(seg_dir, f"{name}_segmentation.jpg")
      norm_path = os.path.join(norm_dir, f"{name}_normalized.jpg")
      temp_path = os.path.join(temp_dir, f"{name}_template.npz")
      code_path = os.path.join(code_dir, f"{name}_code.jpg")
      if save_visuals:
        # Save segmentation result
        canvas = iris_visualizer.plot_segmentation_map(
            ir_image=iris.IRImage(img_data=img_pixels, eye_side="right"),
            segmap=iris_pipeline.call_trace['segmentation'],
        )
        plt.savefig(seg_path, bbox_inches='tight')
        plt.clf()
        # Save normalization result
        canvas = iris_visualizer.plot_normalized_iris(
            normalized_iris=iris_pipeline.call_trace['normalization'],
            )
        plt.savefig(norm_path, bbox_inches='tight')
        plt.clf()

        # Save printed Templates
        canvas = iris_visualizer.plot_iris_template(
            iris_template=iris_pipeline.call_trace['encoder'],
        )
        plt.savefig(code_path, bbox_inches='tight')
        plt.clf()

        # Save templates as npz
        iris_code = output['iris_template'].iris_codes[0]
        mask_code = output['iris_template'].iris_codes[1]
        np.savez_compressed(temp_path, iris_code = iris_code, mask_code = mask_code)
    except Exception as e:
      print(f"Error processing {img_path}: {e}")

pipeline()

# !zip -r /content/outputs.zip /content/outputs

print("Initialising Iris Pipeline")
iris_pipeline = iris.IRISPipeline(env=iris.IRISPipeline.DEBUGGING_ENVIRONMENT)

# init visualizer
print("Initialising Iris Visualizer")
iris_visualizer = iris.visualisation.IRISVisualizer()

image = cv2.imread("/content/Dummy/001_1_1.jpg", cv2.IMREAD_GRAYSCALE)
iris_image = iris.IRImage(img_data=image, image_id="001_1_1", eye_side="left")
output = iris_pipeline(iris_image)

print(output.keys())
print(output['iris_template'].iris_codes[0].shape)

#print(output['metadata'])

#print(output['iris_template'])
iris_code = output['iris_template'].iris_codes[0]
#print(iris_code)
mask_code = output['iris_template'].iris_codes[1]
#print(mask_code)

np.savez_compressed('iris_template.npz', iris_code = iris_code, mask_code = mask_code)

# Load back
data = np.load("iris_template.npz", allow_pickle=True)
iris_code_new = data['iris_code']
mask_code_new = data['mask_code']

assert np.array_equal(iris_code, iris_code_new)
assert np.array_equal(mask_code, mask_code_new)
print("This line should be executed.")